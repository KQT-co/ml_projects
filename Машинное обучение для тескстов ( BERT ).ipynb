{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5e405db",
   "metadata": {},
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b1bbce",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» c BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c89ec17",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461f2aeb",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85e34c7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from transformers) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: requests in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests->transformers) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: torch in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ilya\\anaconda3\\envs\\practicum\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c2e7d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib as mpl\n",
    "import torch\n",
    "import transformers as ppb # pytorch transformers\n",
    "from tqdm import notebook\n",
    "import warnings\n",
    "\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.metrics import (r2_score,\n",
    "                             mean_absolute_error,\n",
    "                             mean_squared_error,\n",
    "                             precision_score,\n",
    "                             recall_score,\n",
    "                             accuracy_score,\n",
    "                             f1_score,\n",
    "                             fbeta_score,\n",
    "                             roc_curve,\n",
    "                             roc_auc_score,\n",
    "                             RocCurveDisplay,\n",
    "                             confusion_matrix,\n",
    "                             ConfusionMatrixDisplay,\n",
    "                             make_scorer\n",
    "                            )\n",
    "\n",
    "\n",
    "from sklearn.model_selection import (train_test_split,\n",
    "                                     GridSearchCV,\n",
    "                                     RandomizedSearchCV,\n",
    "                                     cross_val_score\n",
    "                                    )\n",
    "\n",
    "from sklearn.preprocessing import (StandardScaler,\n",
    "                                   MinMaxScaler,\n",
    "                                   RobustScaler,\n",
    "                                   OneHotEncoder,\n",
    "                                   LabelEncoder,\n",
    "                                   OrdinalEncoder\n",
    "                                  )\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.25\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sb.set(style = 'whitegrid')\n",
    "sb.set(rc={'figure.figsize':(16,9)})\n",
    "sb.set_context('paper', rc={'font.size': 10,\n",
    "                             'axes.titlesize': 10,\n",
    "                             'xtrick.labelsize': 'small',\n",
    "                             'ytrick.labelsize': 'small',\n",
    "                             'legend.fontsize': 'small',\n",
    "                             'legend.title_fontsize':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b6c9e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('C:/Users/Ilya/Downloads/toxic_comments.csv', header=None)\n",
    "\n",
    "\n",
    "try:\n",
    "\n",
    "    data = pd.read_csv('C:/Users/Ilya/Downloads/toxic_comments.csv', header=None)\n",
    "\n",
    "except:\n",
    "\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d24cda33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0                                                  1      2\n",
       "0  NaN                                               text  toxic\n",
       "1  0.0  Explanation\\nWhy the edits made under my usern...      0\n",
       "2  1.0  D'aww! He matches this background colour I'm s...      0\n",
       "3  2.0  Hey man, I'm really not trying to edit war. It...      0\n",
       "4  3.0  \"\\nMore\\nI can't make any real suggestions on ...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159293 entries, 0 to 159292\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   0       159292 non-null  float64\n",
      " 1   1       159293 non-null  object \n",
      " 2   2       159293 non-null  object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "display(data.head())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3445fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(0,axis=1)\n",
    "data = data.drop(0,axis=0)\n",
    "\n",
    "data_droped = data.copy()\n",
    "data_droped = data_droped[data_droped[1].str.len() <= 500] \n",
    "\n",
    "batch_1 = data_droped[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0eaaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2\n",
       "0    1771\n",
       "1     229\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1[2].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f6b1e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество строк в labels_train по классам: [109098  13834]\n",
      "Количество строк в labels_test по классам: [2227  282]\n"
     ]
    }
   ],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "    data_droped[1],\n",
    "    data_droped[2], \n",
    "    train_size=0.98, \n",
    "    random_state=42,\n",
    "    stratify=data_droped[2])\n",
    "\n",
    "print(f\"Количество строк в labels_train по классам: {np.bincount(labels_train)}\")\n",
    "print(f\"Количество строк в labels_test по классам: {np.bincount(labels_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7485b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', None)  # Отключаем ограничение ширины колонки\n",
    "# batch_1.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ce094b",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ed0c3f",
   "metadata": {},
   "source": [
    "### Обучение BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b3cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "# tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "# model = model_class.from_pretrained(pretrained_weights)\n",
    "\n",
    "model = ppb.AutoModel.from_pretrained('unitary/toxic-bert')\n",
    "tokenizer = ppb.AutoTokenizer.from_pretrained('unitary/toxic-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "158db22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = features_test.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87d18b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ed8ea3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2509, 166)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ed87826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2509, 166)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee8e567f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b18c7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5841c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c96db8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c67a12a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24cf4505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lr_clf.f1_score(test_features, test_labels)\n",
    "pred_labels=pd.Series(lr_clf.predict(test_features))\n",
    "test_labels = [int(label) for label in test_labels]\n",
    "pred_labels = [int(label) for label in pred_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dc109f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.95\n"
     ]
    }
   ],
   "source": [
    "print('f1_score: %.2f' % f1_score(test_labels, pred_labels))  #,average='weighted'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e6113",
   "metadata": {},
   "source": [
    "### Обучение с использованием эмбандингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a18a66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e00ea4715744709be1fe32f982b5b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "embeddings = []\n",
    "padded_2 = padded\n",
    "\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    # Создание батчей\n",
    "    batch = torch.tensor(padded[batch_size * i:batch_size * (i + 1)], dtype=torch.long)\n",
    "    attention_mask_batch = torch.tensor(attention_mask[batch_size * i:batch_size * (i + 1)], dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "    embeddings.append(batch_embeddings[0][:, 0, :].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99783b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.98\n"
     ]
    }
   ],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "\n",
    "labels_test_1 = labels_test[:2500]\n",
    "\n",
    "X = features\n",
    "y = labels_test_1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    " X, y, test_size=0.5, random_state=RANDOM_STATE\n",
    ")\n",
    " \n",
    "\n",
    "lr_clf_1 = LogisticRegression()\n",
    "lr_clf_1.fit(X_train, y_train)\n",
    "    \n",
    " #lr_clf.f1_score(test_features, test_labels)\n",
    "y_pred=pd.Series(lr_clf.predict(X_test))\n",
    "y_test = [int(label) for label in y_test]\n",
    "y_pred = [int(label) for label in y_pred]   \n",
    "\n",
    "print('f1_score: %.2f' % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427b470b",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a21add5",
   "metadata": {},
   "source": [
    "Для выполнения задания была обучена модель логистической регрессии, показатель f1 - 0.8 , что соответствует техническому заданию. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
